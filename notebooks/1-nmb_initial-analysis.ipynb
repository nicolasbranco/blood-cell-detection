{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis\n",
    "\n",
    "## Executive summary\n",
    "\n",
    "- most important bullet points\n",
    "- the train dataset was modified to be used in this study\n",
    "- not all images seem to be perfectly annotated\n",
    "\n",
    "## More information\n",
    "\n",
    "**1 - restructure of the validation and train datasets**\n",
    "\n",
    "As observed and explained on the dataset & paper, the validation dataset was a part of the training set. However this makes no sense. Because of that, the current train will be renamed as train+val and the new train_fixed will be the original dataset without the validation images. This structure fixed the methodological mistake done originally in the dataset (validating in training data).\n",
    "\n",
    "**2 - EDA**\n",
    "\n",
    "From the images it is possible to see that the labels and annotations might not be perfect, some seem not to be perfectly annotated, some missing, and such. With that, the model can be only as good as the input data, so that might be a upper limit to its performance.\n",
    "\n",
    "- xxxx\n",
    "- xxxx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports & configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### default imports ####\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### specific imports ###\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "# forces local code to be reloaded to avoid problems\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#### important configs ####\n",
    "# uses seaborn configs for prettier graphs\n",
    "sns.set_theme()\n",
    "# shows thousand separator for values\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "# enable import from src/\n",
    "sys.path.append('..')  \n",
    "\n",
    "#### paths ####\n",
    "# change path to base folder\n",
    "project_path = \"/mnt/c/Users/nicol/My Drive/personal/coding projects/2024/blood-cell-detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## auxiliar functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    sample_annotations = []\n",
    "\n",
    "    for neighbor in root.iter(\"object\"):\n",
    "        label = neighbor.find(\"name\").text\n",
    "        xmin = int(neighbor.find(\"bndbox\").find(\"xmin\").text)\n",
    "        ymin = int(neighbor.find(\"bndbox\").find(\"ymin\").text)\n",
    "        xmax = int(neighbor.find(\"bndbox\").find(\"xmax\").text)\n",
    "        ymax = int(neighbor.find(\"bndbox\").find(\"ymax\").text)\n",
    "\n",
    "        #     print(xmin, ymin, xmax, ymax)\n",
    "        sample_annotations.append([label, xmin, ymin, xmax, ymax])\n",
    "\n",
    "    return sample_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - data prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nicol/My Drive/personal/coding projects/2024/blood-cell-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/branco/miniconda3/envs/bc_detec/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd {project_path}\n",
    "\n",
    "# # clone dataset in the data/raw folder\n",
    "# if os.path.exists('data/'):\n",
    "#     os.removedirs('data/')\n",
    "# os.makedirs('data/processed')\n",
    "# os.makedirs('data/raw')\n",
    "\n",
    "# %cd \"data/raw\"\n",
    "\n",
    "# !git clone git@github.com:MahmudulAlam/Complete-Blood-Cell-Count-Dataset.git\n",
    "\n",
    "# %cd {project_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - validation dataset problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # where the images & labels are\n",
    "# raw_path = \"data/raw/Complete-Blood-Cell-Count-Dataset\"\n",
    "\n",
    "# # gets the path for all files\n",
    "# df_all = pd.DataFrame()\n",
    "# for dirname, _, filenames in os.walk(raw_path):\n",
    "#     paths = [dirname + \"/\" + filename for filename in filenames]\n",
    "#     folder_name = os.path.split(dirname)[-1]\n",
    "#     df_all = pd.concat([df_all, pd.DataFrame({\"path\": paths})], ignore_index=True)\n",
    "\n",
    "# # transforms to df\n",
    "# df_all = pd.DataFrame(df_all)\n",
    "\n",
    "# # also gets the filename\n",
    "# df_all[\"filename\"] = df_all[\"path\"].apply(lambda s: s.split(\"/\")[-1])\n",
    "\n",
    "# # and finally check possible extensions\n",
    "# extensions = df_all[\"path\"].apply(lambda s: s.split(\".\")[-1])\n",
    "# extensions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creates a reference for the dataset (which folder it is from)\n",
    "# df_all[\"dataset\"] = df_all[\"path\"].apply(lambda s: s.split(\"/\")[-3])\n",
    "# df_all[\"dataset\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if all the files in validation dataset are also in the training one\n",
    "# for filename in df_all[df_all[\"dataset\"] == \"Validation\"][\"filename\"]:\n",
    "#     if filename not in df_all[df_all[\"dataset\"] == \"Training\"][\"filename\"].values:\n",
    "#         print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Here it is possible to observe that all files in the validation folder are (as explained in the paper & GitHub) duplicated from the training dataset. This utilization is a methodological problem, so will not be used in our study as it is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select only images\n",
    "# images = df_all[df_all[\"filename\"].apply(lambda s: s.split(\".\")[-1] in [\"jpg\"])]\n",
    "\n",
    "# label_colors = {\"RBC\": \"red\", \"WBC\": \"white\", \"Platelets\": \"purple\"}\n",
    "\n",
    "# # show 3 images\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# for i, (index, row) in enumerate(images.sample(3, random_state=42).iterrows()):\n",
    "#     # img show\n",
    "#     img = plt.imread(row[\"path\"])\n",
    "#     ax[i].imshow(img)\n",
    "#     ax[i].axis(\"off\")\n",
    "#     ax[i].set_title(f\"{row['dataset']} - {row['filename']}\")\n",
    "\n",
    "#     # get annotations\n",
    "#     annotations = get_annotations(\n",
    "#         row[\"path\"].replace(\"Images\", \"Annotations\").replace(\"jpg\", \"xml\")\n",
    "#     )\n",
    "#     print(annotations)\n",
    "\n",
    "#     # show annotations\n",
    "#     for label, xmin, ymin, xmax, ymax in annotations:\n",
    "#         ax[i].add_patch(\n",
    "#             # plt.Rectangle(\n",
    "#             #     (xmin, ymin),\n",
    "#             #     xmax - xmin,\n",
    "#             #     ymax - ymin,\n",
    "#             #     linewidth=2,\n",
    "#             #     edgecolor=label_colors[label],\n",
    "#             #     facecolor=\"none\",\n",
    "#             # )\n",
    "#             Ellipse(\n",
    "#                 ((xmin + xmax) / 2, (ymin + ymax) / 2),\n",
    "#                 xmax - xmin,\n",
    "#                 ymax - ymin,\n",
    "#                 linewidth=2,\n",
    "#                 edgecolor=label_colors[label],\n",
    "#                 facecolor=\"none\",\n",
    "#             )\n",
    "#         )\n",
    "#         ax[i].text(xmin, ymin, label, fontsize=12, color=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Info:** From the images it is possible to see that the labels and annotations might not be perfect, some seem not to be perfectly annotated, some missing, and such. With that, the model can be only as good as the input data, so that might be a upper limit to its performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - creating datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .1 - adapting train, val & test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # coping all the datasets to the processed folder\n",
    "# !cp -r data/raw/Complete-Blood-Cell-Count-Dataset/Training data/processed/Training\n",
    "# !cp -r data/raw/Complete-Blood-Cell-Count-Dataset/Validation data/processed/Validation\n",
    "# !cp -r data/raw/Complete-Blood-Cell-Count-Dataset/Testing data/processed/Testing\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # removing the duplicated images from the training dataset\n",
    "# removed_files = 0\n",
    "# for validation_file_path in df_all[df_all[\"dataset\"] == \"Validation\"][\"path\"]:\n",
    "#     validation_file_path_processed_folder = validation_file_path.replace(\n",
    "#         \"raw\", \"processed\"\n",
    "#     ).replace(\"Complete-Blood-Cell-Count-Dataset/\", \"\")\n",
    "\n",
    "#     if os.path.exists(\n",
    "#         validation_file_path_processed_folder.replace(\"Validation\", \"Training\")\n",
    "#     ):\n",
    "#         os.remove(\n",
    "#             validation_file_path_processed_folder.replace(\"Validation\", \"Training\")\n",
    "#         )\n",
    "#         removed_files += 1\n",
    "\n",
    "# print(f\"Removed {removed_files} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename Images folders to images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .2 - verify and recreate df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # where the images & labels are\n",
    "# processed_path = \"data/processed\"\n",
    "\n",
    "# # gets the path for all files\n",
    "# df_processed = pd.DataFrame()\n",
    "# for dirname, _, filenames in os.walk(processed_path):\n",
    "#     paths = [dirname + \"/\" + filename for filename in filenames]\n",
    "#     folder_name = os.path.split(dirname)[-1]\n",
    "#     df_processed = pd.concat(\n",
    "#         [df_processed, pd.DataFrame({\"path\": paths})], ignore_index=True\n",
    "#     )\n",
    "\n",
    "# # transforms to df\n",
    "# df_processed = pd.DataFrame(df_processed)\n",
    "\n",
    "# # also gets the filename\n",
    "# df_processed[\"filename\"] = df_processed[\"path\"].apply(lambda s: s.split(\"/\")[-1])\n",
    "\n",
    "# # and finally check possible extensions\n",
    "# extensions = df_processed[\"path\"].apply(lambda s: s.split(\".\")[-1])\n",
    "# extensions.value_counts()\n",
    "\n",
    "# processed_images = df_processed[\n",
    "#     df_processed[\"filename\"].apply(lambda s: s.split(\".\")[-1] in [\"jpg\"])\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if all the files in validation dataset are also in the training one\n",
    "# for filename in df_all[df_all[\"dataset\"] == \"Validation\"][\"filename\"]:\n",
    "#     if filename not in df_all[df_all[\"dataset\"] == \"Training\"][\"filename\"].values:\n",
    "#         print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation images & labels were removed from the training dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .2 - creating labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # definitions for the dataset\n",
    "# WIDTH = 640\n",
    "# HEIGHT = 480\n",
    "# cells_id = {\"RBC\": 0, \"WBC\": 1, \"Platelets\": 2}\n",
    "\n",
    "# cells_classes = list(cells_id.keys())\n",
    "# cells_classes\n",
    "# # saves the dataset into the yolo format\n",
    "# for i, (index, row) in enumerate(processed_images.iterrows()):\n",
    "#     # get annotations\n",
    "#     annotations = get_annotations(\n",
    "#         row[\"path\"].replace(\"Images\", \"Annotations\").replace(\"jpg\", \"xml\")\n",
    "#     )\n",
    "\n",
    "#     # get label path\n",
    "#     label_path = row[\"path\"].replace(\"Images\", \"labels\").replace(\"jpg\", \"txt\")\n",
    "\n",
    "#     # create folders\n",
    "#     os.makedirs(os.path.split(label_path)[0], exist_ok=True)\n",
    "\n",
    "#     # save annotations\n",
    "#     with open(label_path, \"w\") as file:\n",
    "#         for label, xmin, ymin, xmax, ymax in annotations:\n",
    "#             # get the center of the rectangle\n",
    "#             x_center = (xmin + xmax) / 2\n",
    "#             y_center = (ymin + ymax) / 2\n",
    "\n",
    "#             # normalize the values\n",
    "#             x_center /= WIDTH\n",
    "#             y_center /= HEIGHT\n",
    "#             width = (xmax - xmin) / WIDTH\n",
    "#             height = (ymax - ymin) / HEIGHT\n",
    "\n",
    "#             # save the values\n",
    "#             file.write(f\"{cells_id[label]} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .3 - create dataset yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_file = \"data/processed/blood_cell_dataset.yaml\"\n",
    "\n",
    "# full_path = \"/mnt/c/Users/nicol/My Drive/personal/coding projects/2024/blood-cell-detection/data/processed\"\n",
    "# train_images_dir = \"Training/images/\"\n",
    "# val_images_dir = \"Validation/images/\"\n",
    "# test_images_dir = \"Testing/images/\"\n",
    "\n",
    "# names_str = \"\"\n",
    "# for item in cells_classes:\n",
    "#     names_str = names_str + \", '%s'\" % item\n",
    "# names_str = \"names: [\" + names_str[1:] + \"]\"\n",
    "\n",
    "# with open(yaml_file, \"w\") as wobj:\n",
    "#     wobj.write(\"path: %s\\n\" % full_path)\n",
    "#     wobj.write(\"train: %s\\n\" % train_images_dir)\n",
    "#     wobj.write(\"val: %s\\n\" % val_images_dir)\n",
    "#     # wobj.write(\"test: %s\\n\" % test_images_dir)\n",
    "#     wobj.write(\"nc: %d\\n\" % len(cells_classes))\n",
    "#     wobj.write(names_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .1 - initial baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.34 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.8 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=models/yolov8n.pt, data=data/processed/blood_cell_dataset.yaml, epochs=3, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train31, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/branco/runs/detect/train31\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Users/nicol/My Drive/personal/coding projects/2024/blood-cell-detection/data/processed/Training/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|██████████| 240/240 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/nicol/My Drive/personal/coding projects/2024/blood-cell-detection/data/processed/Validation/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|██████████| 60/60 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"models/yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "results = model.train(\n",
    "    data=\"data/processed/blood_cell_dataset.yaml\", epochs=3, imgsz=640, batch=4\n",
    ")\n",
    "\n",
    "# show results\n",
    "for dataset in [\"train\", \"val\"]:\n",
    "    print(\"-\" * 30)\n",
    "    print(dataset)\n",
    "    results = model.val(split=dataset)\n",
    "    print(results.results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .2 - hyperparam tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .3 - pre & post-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - boxes on same location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - confidence of result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C - model to predict this part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - model results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Analisys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc_detec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
